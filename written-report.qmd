---
title: "Predicting a Pokémon's Strength Using Variables Other Than Base Stats"
author: "STA 210 BDN: Nate Krall, Daniel Cohen, Brian Kim"
date: "12/01/2023"
format: pdf
execute: 
  warning: false
  message: false
  echo: false
editor: visual
---

```{r warning = F, echo = F}
#| label: load packages and data
library(tidyverse)
library(tidymodels)
library(ggplot2)
library(dplyr)
library(patchwork)
library(knitr)
library(rms)
library(kableExtra)


pokemon <- read.csv("data/pokemon.csv")
pokemon <- pokemon[-774, ]
pokemon$capture_rate <- as.integer(pokemon$capture_rate)
```

## Introduction and Data:

A deeper look into the numbers in the game of Pokemon shows a game filled relationships among several characteristics of the pokemon. Each creature has its own specific set of base statistics, colloquially referred to as "base stats," including attack, special attack, defense, special defense, and speed, which indicate that pokémon's battle prowess. Summing these stats yields a pokémon's total base stats, the best measure of a pokémon's overall strength -- common knowledge for any pokémon fan. We are looking to answer the following research question: **Can we predict a Pokémon's Base Stat Total from other variables?** We are analyzing how well variables such as the pokémon's type, capture rate, growth rate, generation, height, weight, base happiness, and weaknesses can predict a pokémon's total base stats. We hypothesize that a multiple linear regression model will be a somewhat strong predictor for base_total -- thinking about the game, stronger pokémon would seem to have certain values for these predictor variables when compared to weaker ones: for example, legendary pokémon tend to be stronger in battle than non legendary pokémon, so we might expect is_legendary to be a useful predictor for base_total. We retrieved the dataset from kaggle.com, a large data science online community, and the dataset is called ["The Complete Pokemon Dataset"](https://labs-az-08.oit.duke.edu:30269/#0) created by Rounak Banik in 2017. The dataset was retrieved via web scraper from the website serebii.net. Since it was formed in 2017, the dataset does not include pokémon from more recent games, but still includes 801 pokémon, meaning the dataset has 801 observations. However, note that we removed one pokémon from the original 801 pokémon, Minior, from the dataset, since it has 2 different forms and has an uninterpretable capture rate. R automatically translated the \*capture_rate\* variable to characters because Minior's capture rate was listed as: "30 (Meteorite)255 (Core)". We decided to exclude this observation from the model because of its uninterpretable characteristics, and after, we casted \*capture_rate\* an integer instead of a character. The dataset contains 23 variables, explanations of which can be viewed in our [data dictionary](./data/README.md). We will be focusing on these variables:

**RESPONSE VARIABLE:** base_total: total base stats of the Pokemon \[whole number\]

**PREDICTOR VARIABLES**

-   experience_growth: The Experience Growth of the Pokemon \[whole number\]

-   base_egg_steps: \# of steps required to hatch an egg of the Pokemon \[whole number\]

-   base_happiness: Base Happiness of the Pokemon \[whole number\]

-   capture_rate: Capture Rate of the Pokemon \[whole number\]

-   generation: The generation which the Pokemon was introduced \[whole number 1-7\]

-   height_m: Height of the Pokemon \[number in meters\]

-   percentage_male: % of the species that are male \[percent, blank if no gender\]

-   pokedex_number: Entry \# of the Pokemon in the Pokedex \[between 1-801\]

-   type1, type2: The Primary Type and Second Type of the Pokemon, respectively

-   weight_kg: The Weight of the Pokemon \[number in kilograms\]

-   is_legendary: Denotes if the Pokemon is legendary.\[0 = not legendary, 1 = legendary\]

The dataset splits the base stats of each pokémon into the individual stats, but we only need to know about the base_total. Some variables like is_legendary, may prove to be extremely important in our regression model, while others that are simply identifiers can be removed.

**Exploratory Data Analysis**

```{r expdata1, warning = F, echo = F}
p1 <- ggplot(pokemon, aes(x = base_total)) +
  geom_histogram(binwidth = 10, fill = "blue", color = "black") +
  geom_vline(xintercept = mean(pokemon$base_total), color = "red", size = 1) +
  labs(title = "Distr. of Base Total", x = "Base Total")
```

```{r expdata3, warning = F, echo = F}
generation_means <- pokemon |>
  group_by(generation) |>
  summarise(mean_base_total = mean(base_total)) |>
  arrange(desc(mean_base_total))

p3 <- ggplot(generation_means, aes(x = as.factor(generation), y = mean_base_total)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  labs(title = "Mean Base Total Across Generations",
       x = "Generation",
       y = "Mean Base Total")
```

```{r expdata4, warning = F, echo = F}
p4 <- ggplot(pokemon, aes(x = weight_kg, y = base_total)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, col = "blue") +
  labs(title = "Base Total vs. Weight", x = "Weight (kg)", y = "Base Total")
```

```{r expdata6, warning = F, echo = F}
pokemon$is_legendary <- as.factor(pokemon$is_legendary)
p6 <- ggplot(pokemon, aes(x = weight_kg, y = base_total, color = is_legendary)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Weight and Legendary Status Interaction", x = "Weight (kg)", y = "Base Total")
```

```{r plots, message = F, warning = F, echo = F}
p1 <- p1 + theme(
  plot.title = element_text(size = rel(0.8)), # Adjust plot title size
  axis.title.x = element_text(size = rel(0.8)),     # X axis label
  axis.title.y = element_text(size = rel(0.8)),     # Y axis label
  axis.text.x = element_text(size = rel(0.8)),      # X axis text
  axis.text.y = element_text(size = rel(0.8)),      # Y axis text
  legend.title = element_text(size = rel(0.8)),     # Legend title
  legend.text = element_text(size = rel(0.8))       # Legend text
)

p3 <- p3 + theme(
  plot.title = element_text(size = rel(0.8)), # Adjust plot title size
  axis.title.x = element_text(size = rel(0.8)),     # X axis label
  axis.title.y = element_text(size = rel(0.8)),     # Y axis label
  axis.text.x = element_text(size = rel(0.8)),      # X axis text
  axis.text.y = element_text(size = rel(0.8)),      # Y axis text
  legend.title = element_text(size = rel(0.8)),     # Legend title
  legend.text = element_text(size = rel(0.8))       # Legend text
)

p4 <- p4 + theme(
  plot.title = element_text(size = rel(0.8)), # Adjust plot title size
  axis.title.x = element_text(size = rel(0.8)),     # X axis label
  axis.title.y = element_text(size = rel(0.8)),     # Y axis label
  axis.text.x = element_text(size = rel(0.8)),      # X axis text
  axis.text.y = element_text(size = rel(0.8)),      # Y axis text
  legend.title = element_text(size = rel(0.8)),     # Legend title
  legend.text = element_text(size = rel(0.8))       # Legend text
)

p6 <- p6 + theme(
  plot.title = element_text(size = rel(0.8)), # Adjust plot title size
  axis.title.x = element_text(size = rel(0.8)),     # X axis label
  axis.title.y = element_text(size = rel(0.8)),     # Y axis label
  axis.text.x = element_text(size = rel(0.8)),      # X axis text
  axis.text.y = element_text(size = rel(0.8)),      # Y axis text
  legend.title = element_text(size = rel(0.8)),     # Legend title
  legend.text = element_text(size = rel(0.8))       # Legend text
)
plot_combined <- (p1 | p3) /
(p4 | p6)

plot_final <- plot_combined + 
              plot_layout(widths = c(1, 1, 1), heights = c(1, 1))
plot_combined
```

```{r summaryTotal, message = F, warning = F, echo = F}
tidy(summary(pokemon$base_total)) |>
  kable(digits=3)
```

**p1: Distribution of Base total:** The distribution of the base total seems to be roughly trimodal with three peaks (one around 300, 400, and 475). The base total points vary from about 180 to 780. Since there is an outlier around 780 base total, we use the median of 435 to describe the center of the data. The IQR is 185 (505 - 320).

**p2: Mean Base Total Across Generations:** This is the graph showing the relationship between different generation Pokemon and mean base total. The mean base total of generation 4 Pokemon were the highest. There is a slight positive linear relationship between the generation of the Pokemon and their mean base total.

**p3: Scatter Plot of Base Total vs Weight:** From the scatter plot we can see that there is no apparent correlation between the weight and the base total. There seems to be a few outliers near 900-1000kg.

**p4: Interaction Between Weight and Legendary Status:** This graph depicts how Pokémon weight correlates with base totals for both legendary (blue line) and non-legendary (red line) Pokémon. Legendary Pokémon typically have higher base totals (550-700), regardless of weight, showing no clear weight-related trend. On the other hand, non-legendary Pokémon exhibit a slight positive correlation; as their weight increases, their base total marginally rises. This distinction in base stat totals between legendary and non-legendary Pokémon will be reflected in our model.

## Methodology:

We are conducting a multiple linear regression model to predict base_total from several other predictor variables. Any form of logistic regression would not make sense in this case as base_total is a quantitative variable, meaning we are not making classifications, and thus MLR is the model we conduct.

```{r}
set.seed(123)
pokemon_split <- initial_split(pokemon)
pokemon_train <- training(pokemon_split)
pokemon_test <- testing(pokemon_split)
```

We randomly split our data into 75% training and 25% testing data to both train and evaluate our model.

```{r}
pokemon_rec_full <- recipe(base_total ~ ., data = pokemon_train) |> #make name's role ID 
  update_role(name, new_role = "ID") |> 
  #remove abilities 
  step_rm(abilities) |> 
  #remove all "against" variables to eliminate redundancy & collinearity 
  step_rm(against_bug, against_dark, against_dragon, against_electric, against_fairy, against_fight, against_fire, against_flying, against_ghost, against_grass, against_ground, against_ice, against_normal, against_poison, against_psychic, against_rock, against_steel, against_water ) |>
  #remove types (for now)
   step_rm(type1, type2) |>
  #remove classification 
  step_rm(classfication) |> 
  #remove all individual stats 
  step_rm(attack, defense, hp, sp_attack, sp_defense, speed) |> 
  #remove japanese name 
  step_rm(japanese_name) |>
  step_rm(percentage_male) |>
    step_normalize(experience_growth) |>
   step_center(experience_growth,
              base_egg_steps,
              base_happiness,
              capture_rate,
              experience_growth,
              height_m,
              pokedex_number,
              weight_kg,
              generation) |>
  step_naomit(height_m)
```

Next, we take the training data through a recipe to ready it for our analysis.

1.  We update the role of "name" to be an ID. Name is simply a label for each observation.

2.  We remove irrelevant, non-predicting information like abilities, classification, and Japanese name.

    -   There are hundreds of different abilities a Pokemon can have, and very little overlap of abilities between Pokemon, so we do not need the abilities variable. The classification of a Pokemon is almost unique for every Pokemon (there is very little overlap), and it mainly just groups Pokemon by their evolution line, yielding classification unwanted.

3.  We remove all against\_\* variables and all type variables, as these variables convey the same info.

4.  We mean-center all quantitative predictors so our intercept is interpretable.

5.  We address missing data in the height/weight category:

    -   There are 20 Pokemon with missing height and weight values. Per the author of the database, these 20 Pokemon have alternate regional forms where their height and weights differ from their normal form, creating a disparity between these 20 Pokemon and the rest of the Pokemon in the dataset. Thus, we decided to remove these 20 Pokemon from consideration.

6.  Finally, we remove percentage_male from consideration.

    -   Several Pokemon do not have a gender, leading to many missing values in the dataset. Upon further examination, we found that a disproportionate 63/70 of the legendary Pokemon in the dataset to not have a gender, whereas most non-legendary pokémon do have a gender. Percentage_male and is_legendary cannot be effective predictors in conjunction, so we decide to remove percentage_male from our model.

Note that pokédex number is in fact a unique identifier for a pokémon, yet it also contains information on when the pokémon was released in-game, as larger pokédex numbers correspond to later releases, which may have a tie to base_total. Also, generation may seem as if it is an arbitrary label, but it also corresponds to when a pokémon was released in a different manner than pokédex number. We are wary of the potential of collinearity among these variables and will analyze the substantiallity of their collinearity (as well as all other potential predictors) in our analysis.

```{r}
pokemon_spec_full <- linear_reg() |>
  set_engine("lm")

pokemon_wflow_full <- workflow() |>
  add_model(pokemon_spec_full) |>
  add_recipe(pokemon_rec_full)
```

After bringing the training data through our recipe, we fit the data in a MLR model:

```{r}
pokemon_fit_full <- pokemon_wflow_full |>
  fit(data = pokemon_train)

tidy(pokemon_fit_full) |>
  kable(digits = 3)
```

Base_egg_steps, base_happiness, and weight_kg are three candidates for variables to remove from the model, since we notice their p-values are all \> .05, meaning they are potentially statistically insignificant predictors. The next step in our method is compare two models through a series of tests: the one model being our original model with all predictors after running our feature engineering, and one with those varibale removed to select a model that strikes a balance between conciseness and detail, or select the most comprehensive one available.

```{r}
pokemon_rec_less <- recipe(base_total ~ ., data = pokemon_train) |> #make name's role ID 
  update_role(name, new_role = "ID") |> 
  #remove abilities 
  step_rm(abilities) |> 
  #remove all "against" variables to eliminate redundancy & collinearity 
  step_rm(against_bug, against_dark, against_dragon, against_electric, against_fairy, against_fight, against_fire, against_flying, against_ghost, against_grass, against_ground, against_ice, against_normal, against_poison, against_psychic, against_rock, against_steel, against_water ) |>
  #remove types (for now)
   step_rm(type1, type2) |>
  #remove classification 
  step_rm(classfication) |> 
  #remove all individual stats 
  step_rm(attack, defense, hp, sp_attack, sp_defense, speed) |> 
  #remove japanese name 
  step_rm(japanese_name) |>
  step_rm(percentage_male) |>
  #center all quantitative predictors
  step_center(experience_growth,
              base_egg_steps,
              base_happiness,
              capture_rate,
              experience_growth,
              height_m,
              pokedex_number,
              weight_kg,
              generation) |>
  step_rm(base_egg_steps, 
          base_happiness, 
          weight_kg)
```

```{r}
pokemon_spec_less <- linear_reg() |>
  set_engine("lm")

pokemon_wflow_less <- workflow() |>
  add_model(pokemon_spec_less) |>
  add_recipe(pokemon_rec_less)
```

We create a similar recipe for the second model except that base_egg_steps, base_happiness, and weight_kg are removed. The output of running MLR is shown below:

```{r}
pokemon_fit_less <- pokemon_wflow_less |>
  fit(data = pokemon_train)

tidy(pokemon_fit_less) |>
  kable(digits = 3)
```

We then conducted two tests to decipher which model is best to select for our final model: one comparing the AIC, BIC, and adjusted $R^2$ for the models, and another comparing the results of V-fold cross validation for the models. First test output:

```{r}
glance(pokemon_fit_full) |> 
  select(AIC, BIC, adj.r.squared) |>
  kable(digits = 3)
glance(pokemon_fit_less) |> 
  select(AIC, BIC, adj.r.squared) |>
  kable(digits = 3)
```

From this test, we note that both AIC and BIC are lower for the second, reduced model. The adjusted $R^2$ values are very similar in size. It would be logical to select the second model, as it produces more preferable values of AIC and BIC while maintaining a very similar adjusted $R^2$ value. However, we run one more test, v-fold cross validation, to compare the models once again. The results of this second test are below:

Cross validation results for the 1st, full model:

```{r}
set.seed(123)
folds <- vfold_cv(pokemon_train, v = 15)

pokemon_wflowV_full <- workflow() |>
	add_model(pokemon_spec_full) |>
	add_recipe(pokemon_rec_full)

pokemon_fitV_full <- pokemon_wflowV_full |>
	fit_resamples(folds)
collect_metrics(pokemon_fitV_full) |>
  kable(digits = 3)
```

Cross validation for the 2nd, reduced model:

```{r}
pokemon_wflowV_less <- workflow() |>
	add_model(pokemon_spec_less) |>
	add_recipe(pokemon_rec_less)

pokemon_fitV_less <- pokemon_wflowV_less |>
	fit_resamples(folds) 
collect_metrics(pokemon_fitV_less) |>
  kable(digits = 3)
```

We notice that the RMSE value from cross validation of the second model \< the RMSE value from the cross validation of the first full model, while the $R^2$ values from both models have negligible difference, meaning the second model is a better predictor a pokémon's base stat total. From the results of these tests, **we can confidently select model number 2, the reduced model**.

To determine there is no multicollinearity in our model, we must examine the VIF values:

```{r}
#getting VIF numbers. Only worry about multicolinearity if VIFS are greater than 10
pokemon_fitless <- extract_fit_parsnip(pokemon_fit_less)
vif(pokemon_fitless$fit) |>
  tidy() |>
  kable(digits = 3)
```

A VIF value \> 10 for a variable indicates concerning collinearity. We notice that pokedex_number and generation have VIF values \> 40, meaning pokedex_number and generation appear to be collinear. This makes sense -- as generations of pokemon are intervals of pokedex numbers. Generation divides all values 1-800 of pokedex_number into different intervals (for example, generation 1 is pokedex numbers 1-151). To fix this, we deleted generation, since it is far more discrete than pokedex_number.

Our final model is the same as the second model with generation removed.

```{r}
pokemon_rec_final <- recipe(base_total ~ ., data = pokemon) |> #make name's role ID 
  update_role(name, new_role = "ID") |> 
  #remove abilities 
  step_rm(abilities) |> 
  #remove all "against" variables to eliminate redundancy & collinearity 
  step_rm(against_bug, against_dark, against_dragon, against_electric, against_fairy, against_fight, against_fire, against_flying, against_ghost, against_grass, against_ground, against_ice, against_normal, against_poison, against_psychic, against_rock, against_steel, against_water ) |>
  #remove types (for now)
   step_rm(type1, type2) |>
  #remove classification 
  step_rm(classfication) |> 
  #remove all individual stats 
  step_rm(attack, defense, hp, sp_attack, sp_defense, speed) |> 
  #remove japanese name 
  step_rm(japanese_name) |>
  step_rm(percentage_male) |>
  #center all quantitative predictors
  step_center(experience_growth,
              base_egg_steps,
              base_happiness,
              capture_rate,
              experience_growth,
              height_m,
              pokedex_number,
              weight_kg,
              generation) |>
  step_normalize(experience_growth) |>
  step_rm(base_egg_steps, 
          base_happiness, 
          weight_kg,
          generation)
```

```{r}
pokemon_spec_final <- linear_reg() |>
  set_engine("lm")

pokemon_wflow_final <- workflow() |>
  add_model(pokemon_spec_final) |>
  add_recipe(pokemon_rec_final)
```

```{r}
pokemon_fit_final <- pokemon_wflow_final |>
  fit(data = pokemon)
```

```{r}
#getting VIF numbers. Only worry about multicolinearity if VIFS are greater than 10
pokemon_fitless <- extract_fit_parsnip(pokemon_fit_final)
vif(pokemon_fitless$fit) |>
  kable(digits =3)
```

As we can see, the VIF values are all now satisfactorily low for the final model.

```{r}
tidy(pokemon_fit_final) |>
  kable(digits = 3)
```

The equation for the final model is: $$
\begin{split} base\_total = 419.982 - 0.839 * capture\_rate + 2.412* experience\_growth \\  + 28.62 * height\_m + 0.024 * pokedex\_number + 88.596 * is\_legendary1 \end{split}
$$

We can tell that we expect the base total to be 419.982 for a pokémon that is not legendary, with capture_rate, experience_growth, height_m, pokedex_number at their mean values.

For every one unit increase in capture rate, we expect base total to decrease by .839, on average, holding all other predictor variables constant.

For every one unit increase in experience growth, we expect base total to increase by 2.412, on average, holding all other predictor variables constant.

For every one meter increase in height, we expect base total to increase by 28.62, on average, holding all other predictor variables constant.

For every one increase in pokedex number, we expect base total to increase by .024, on average, holding all other predictor variables constant.

We expect a legendary pokemon to have a base total greater than a non legendary pokemon by 88.596, on average, holding all other predictor variables constant.

One interesting observation from our analysis is that the visible qualities, such as height and legendary status, have the most impact on a Pokémon's base total, as indicated by their relatively large coefficients in the regression model. For players, these insights are valuable as they can make assessments of a pokemon's strength based on physical characteristics.

## Results:

```{r}
pokemon_fit_model123 <- extract_fit_parsnip(pokemon_fit_final)
pokemon_aug <- augment(pokemon_fit_model123$fit)

p1 <- ggplot(data = pokemon_aug, aes(x = capture_rate, y = .resid)) +
	geom_point() +
	geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(x = "Capture Rate", y = "Residuals", title = "Residuals vs Capture Rate") +
  theme(plot.title = element_text(size = 11))
p2 <- ggplot(data = pokemon_aug, aes(x = experience_growth, y = .resid)) +
	geom_point() +
	geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(x = "Experience Growth", y = "Residuals", title = "Residuals vs Exp. Growth") +
  theme(plot.title = element_text(size = 11))
p3 <- ggplot(data = pokemon_aug, aes(x = height_m, y = .resid)) +
	geom_point() +
	geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(x = "Height (m)", y = "Residuals", title = "Residuals vs Height(m)") +
  theme(plot.title = element_text(size = 11))
p4 <- ggplot(data = pokemon_aug, aes(x = pokedex_number, y = .resid)) +
	geom_point() +
	geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(x = "Pokedex Number", y = "Residuals", title = "Residuals vs Pokedex Num.") +
  theme(plot.title = element_text(size = 11))
p5 <- ggplot(data = pokemon_aug, aes(x = is_legendary, y = .resid)) +
	geom_point() +
	geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(x = "is Legendary", y = "Residuals", title = "Residuals vs is_Legendary") +
  theme(plot.title = element_text(size = 11))
norm <- ggplot(data = pokemon_aug, aes(x = .resid)) +
  geom_histogram() + 
  labs(title = "Distribution of residuals") +
  theme(plot.title = element_text(size = 11))
pred_resid <- ggplot(data = pokemon_aug, aes(x = .fitted, y = .resid)) +
  labs(title = "Resid. v Fitted") +
  geom_point()
```

```{r}
p1 <- p1 + theme(
  plot.title = element_text(size = rel(0.8)), # Adjust plot title size
  axis.title.x = element_text(size = rel(0.8)),     # X axis label
  axis.title.y = element_text(size = rel(0.8)),     # Y axis label
  axis.text.x = element_text(size = rel(0.8)),      # X axis text
  axis.text.y = element_text(size = rel(0.8)),      # Y axis text
  legend.title = element_text(size = rel(0.8)),     # Legend title
  legend.text = element_text(size = rel(0.8))       # Legend text
)

p2 <- p2 + theme(
  plot.title = element_text(size = rel(0.8)), # Adjust plot title size
  axis.title.x = element_text(size = rel(0.8)),     # X axis label
  axis.title.y = element_text(size = rel(0.8)),     # Y axis label
  axis.text.x = element_text(size = rel(0.8)),      # X axis text
  axis.text.y = element_text(size = rel(0.8)),      # Y axis text
  legend.title = element_text(size = rel(0.8)),     # Legend title
  legend.text = element_text(size = rel(0.8))       # Legend text
)

p3 <- p3 + theme(
  plot.title = element_text(size = rel(0.8)), # Adjust plot title size
  axis.title.x = element_text(size = rel(0.8)),     # X axis label
  axis.title.y = element_text(size = rel(0.8)),     # Y axis label
  axis.text.x = element_text(size = rel(0.8)),      # X axis text
  axis.text.y = element_text(size = rel(0.8)),      # Y axis text
  legend.title = element_text(size = rel(0.8)),     # Legend title
  legend.text = element_text(size = rel(0.8))       # Legend text
)

p4 <- p4 + theme(
  plot.title = element_text(size = rel(0.8)), # Adjust plot title size
  axis.title.x = element_text(size = rel(0.8)),     # X axis label
  axis.title.y = element_text(size = rel(0.8)),     # Y axis label
  axis.text.x = element_text(size = rel(0.8)),      # X axis text
  axis.text.y = element_text(size = rel(0.8)),      # Y axis text
  legend.title = element_text(size = rel(0.8)),     # Legend title
  legend.text = element_text(size = rel(0.8))       # Legend text
)

p5 <- p5 + theme(
  plot.title = element_text(size = rel(0.8)), # Adjust plot title size
  axis.title.x = element_text(size = rel(0.8)),     # X axis label
  axis.title.y = element_text(size = rel(0.8)),     # Y axis label
  axis.text.x = element_text(size = rel(0.8)),      # X axis text
  axis.text.y = element_text(size = rel(0.8)),      # Y axis text
  legend.title = element_text(size = rel(0.8)),     # Legend title
  legend.text = element_text(size = rel(0.8))       # Legend text
)

pred_resid <- pred_resid + theme(
  plot.title = element_text(size = rel(0.8)), # Adjust plot title size
  axis.title.x = element_text(size = rel(0.8)),     # X axis label
  axis.title.y = element_text(size = rel(0.8)),     # Y axis label
  axis.text.x = element_text(size = rel(0.8)),      # X axis text
  axis.text.y = element_text(size = rel(0.8)),      # Y axis text
  legend.title = element_text(size = rel(0.8)),     # Legend title
  legend.text = element_text(size = rel(0.8))       # Legend text
)

norm <- norm + theme(
  plot.title = element_text(size = rel(0.8)), # Adjust plot title size
  axis.title.x = element_text(size = rel(0.8)),     # X axis label
  axis.title.y = element_text(size = rel(0.8)),     # Y axis label
  axis.text.x = element_text(size = rel(0.8)),      # X axis text
  axis.text.y = element_text(size = rel(0.8)),      # Y axis text
  legend.title = element_text(size = rel(0.8)),     # Legend title
  legend.text = element_text(size = rel(0.8))       # Legend text
)

(p5 + pred_resid) /
(norm)

(p1 + p3) / 
(p2 + p4)

```

**Linearity condition** - This condition is satisfied as there is no clear patterns in the residuals vs predictor variables such as a fanning pattern and the fitted vs residuals graph also seems to have no fanning pattern.

**Constant Variance** - The vertical spread of the residuals is constant across the plots of residuals versus fitted values, therefore this condition is satisfied.

**Normality** - The distribution of the residuals is approximately unimodal and symmetric, so the normality condition is satisfied. The sample size is sufficiently large \>\> 30 so we can relax this condition.

**Independence** - The independence condition is **not** satisfied. The independence condition in our Pokémon dataset is not met due to the evolutionary relationships between Pokémon. For instance, Pokémon like Bulbasaur, Ivysaur, and Venusaur share evolutionary lines, leading to non-independent data, as these related Pokémon often have similar types, generations, and correlated base stats. Acknowledging this, our model might be less predictive for independent Pokémon, assuming independent errors, which is not the case here.

Instead of an in-depth analysis on the standard errors for the model coefficients to justify moving forward with conclusions, we choose to elaborate as to why conclusions are irrelevant if we choose one pokemon per evolution chain. We chose not to remove Pokémon from each evolutionary line to maintain dataset integrity and relevance to our research question. Excluding more than half of our Pokémon to meet the independence condition would limit the scope of our conclusions. Our aim is to analyze how various factors predict a Pokémon's base stat total, considering all Pokémon, including those within evolutionary chains, as roughly 75% of Pokémon are part of an evolutionary chain. Limiting our analysis to only the final evolution in each chain would not accurately represent the full spectrum of Pokémon as they exist in the games, and it would detract from the purpose of our study - to understand the predictors of a Pokémon's Base Stat Total across all evolutionary stages.

**Results**

Here are the RMSE and $R^2$ given from K-fold cross validation:

```{r}
pokemon_fit_final <- pokemon_wflow_final |>
	fit_resamples(folds)
collect_metrics(pokemon_fit_final) |>
  kable(digits=3)
```

Here are the RMSE and $R^2$ given from the training set:

```{r, results='asis', echo=FALSE}
pokemon_final_fit_train <- pokemon_wflow_final |>
  fit(data = pokemon_train)

pokemon_train_pred <- predict(pokemon_final_fit_train, pokemon_train) |>
  bind_cols(pokemon_train)

rsq_valueTrain <- rsq(pokemon_train_pred, truth = base_total, estimate = .pred)
rmse_valueTrain <- rmse(pokemon_train_pred, truth = base_total, estimate = .pred)

# Combine tables side by side
knitr::kable(
  cbind(rsq_valueTrain, rmse_valueTrain),
  digits = 3)
```

Here are the RMSE and $R^2$ given from the test set:

```{r, results='asis', echo=FALSE}
pokemon_test_pred <- predict(pokemon_final_fit_train, pokemon_test) |>
  bind_cols(pokemon_test)

rsq_valueTest <- rsq(pokemon_test_pred, truth = base_total, estimate = .pred) 
rmse_valueTest <- rmse(pokemon_test_pred, truth = base_total, estimate = .pred) 

# Combine tables side by side
knitr::kable(
  cbind(rsq_valueTest, rmse_valueTest),
  digits = 3)
```

When we compare the $R^2$ values, that of the training model was .641 while the testing model had a $R^2$ value of .577. This is to be expected since the training data has been trained on so it should be a better predictor than the testing model. When we compare the RMSE for the training and testing data, we can see that the RMSE for the training set was 71.1 while the RMSE of the testing set was 80.69. Since lower RMSE values indicate a better fit to the model and we can see that the RMSE of the testing set was greater than that of the training set which means the training data once again is a better predictor and this is once again to be expected since training data was trained on so it should predict the model better. Since the difference in the $R^2$ and the RMSE values between the training and the testing data wasn't too significant, this shows that our model doesn't over fit the data.

Overall, for our initial interpretations of our final model, we find it to be a relatively strong predictor for base_total of a Pokemon given the relatively low RMSE value and the relatively high $R^2$ value. Thus, we have confirmed our hypothesis that in fact, we *can* predict the base_total of a Pokemon with decent accuracy by using different variables.

## Discussion + Conclusion:

**Summary of Findings:** From the equation of our final model we found out that in order to maximize the base total of our pokemon, we want a lower capture rate, higher experience growth, greater height, larger pokedex number, and want our pokemon to be of the legendary kind. Our research aimed to predict a Pokémon's base stat total. Our analysis revealed statistically significant and statistically insignificant relationships between certain characteristics such as Pokémon's capture rate, whether it is legendary, and generation with the pokemon's overall strength (base total). Our final model which included capture rate, experience growth, height, pokedex number, and legendary status, was not only a good predictor of base_total, accounting for approximately 64.074% of the variability in Base Stat Total in the training data, but also was a concise model, only including statistically significant predictors. The relatively low RMSE value of 72.81 also suggested a satisfactory level of prediction accuracy, as base total ranges from 200 to 800.

**Limitations and Improvement Suggestions:** The dataset was drawn in 2017 does not include pokémon in games released after this date. This means that this model should not be extrapolated past this date as the Pokemon games evolve over time and might affect our applicability of these results to future editions. Additionally, as we talked more in detail about in the previous section, the independence condition being violated limits the predictive power of this model, as evolution chains are not including in our model. While we removed variables like base_egg_steps and base_happiness due to their high p-values, further exploration could determine if any interaction effects or non-linear relationships exist that we might have overlooked.

**Reliability and Validity Concerns:** The linear regression model assumes linearity, independence, homoscedasticity, and normality of residuals, which we proved held for our dataset. Even though our model satisfied these conditions, any violation in future datasets of future Pokemon games could make the model unreliable. Additionally, the data was scraped from a fan-run website, there might be biases or errors in how the information was recorded, affecting the validity.

**Future Work:** To continue our research in the future, we could could include data from newer Pokémon games to keep our model relevant over time. Additionally, analyzing how a Pokémon's evolutionary stage affects its Base Stat Total could be very interesting, especially due to the great variance in Pokemon evolution. For examples, the starter pokémon are generally pretty strong compared to other pokémon their level at all stages in their evolution. On the other hand, Magikarp is possibly the weakest pokémon in the game, but evolves to become Gyarados, one of the strongest pokémon in the game. Additionally, we could have more investigation into the interactive effects between variables, like how the combination of type and legendary status impacts base stats, could provide a deeper understanding of the underlying dynamics.
